{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18767"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'D:\\study\\thesis\\project\\HBDM-main\\data\\datasets\\ppi\\ppi_index.pkl', 'rb') as f:\n",
    "    value_to_index_mapping = pickle.load(f)\n",
    "len(value_to_index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_stringdb = 'D:/study/thesis/project/HBDM-main/data/nn_data/stringdb/'\n",
    "# load local STRING database and names\n",
    "df = pd.read_csv(local_stringdb+'9606.protein.info.v12.0.txt', sep='\\t', header=0, usecols=['#string_protein_id', 'preferred_name'])\n",
    "df['preferred_name'] = df['preferred_name'].str.upper()\n",
    "stringId2name = df.set_index('#string_protein_id')['preferred_name'].to_dict()\n",
    "name2stringId = df.set_index('preferred_name')['#string_protein_id'].to_dict()\n",
    "df = pd.read_csv(local_stringdb+'9606.protein.aliases.v12.0.txt', sep='\\t', header=0, usecols=['#string_protein_id', 'alias']).drop_duplicates(['alias'], keep='first')\n",
    "df['alias'] = df['alias'].str.upper()\n",
    "aliases2stringId = df.set_index('alias')['#string_protein_id'].to_dict()\n",
    "\n",
    "string_score_transform = lambda x: -np.log(x/1000)\n",
    "\n",
    "network = pd.read_csv(local_stringdb+'9606.protein.physical.links.detailed.v12.0.txt', sep=' ', header=0).convert_dtypes().replace(0, float('nan'))\n",
    "network['combined_score'] = network['combined_score'].apply(string_score_transform)\n",
    "\n",
    "def convert_stringId(alias):\n",
    "    try:\n",
    "        stringId = name2stringId[alias]\n",
    "    except:\n",
    "        #print(alias, 'can\\'t be converted by name2stringId! Now trying aliases2stringId.')\n",
    "        try:\n",
    "            stringId = aliases2stringId[alias]\n",
    "        except:\n",
    "            #print(alias, 'can\\'t be converted by aliases2stringId! Now return None.')\n",
    "            stringId = None\n",
    "    #print(alias, stringId)\n",
    "    return stringId\n",
    "\n",
    "def read_string_net_from_df(df, weight_choose='combined_score'): # default combined score\n",
    "    string_net = {}\n",
    "    for row in df.itertuples(index=False):\n",
    "        start_node, end_node, weight = row.protein1, row.protein2, getattr(row, weight_choose)\n",
    "        if start_node not in string_net:\n",
    "            string_net[start_node] = {}\n",
    "        string_net[start_node][end_node] = weight\n",
    "        if end_node not in string_net:\n",
    "            string_net[end_node] = {}\n",
    "        string_net[end_node][start_node] = weight\n",
    "    return string_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\study\\thesis\\project\\HBDM-main\\data\\complexes\\complexes.pkl', 'rb') as f:\n",
    "    complexs = pickle.load(f)\n",
    "protein_names = list(aliases2stringId.keys())\n",
    "protein_names.extend(list(name2stringId.keys()))\n",
    "\n",
    "humans = set(value_to_index_mapping.keys())\n",
    "\n",
    "complexs_id = dict()\n",
    "\n",
    "for complex_name in complexs:\n",
    "    # folder_path = 'D:/study/thesis/project/HBDM-main/ppi_results/test_results/'+complex_name\n",
    "    # os.mkdir(folder_path)\n",
    "    group_node = []\n",
    "    for gene in complexs[complex_name]:\n",
    "        if gene in protein_names:\n",
    "            stringid = convert_stringId(gene)\n",
    "            # stringid = int(stringid[9:])\n",
    "            # if stringid in humans:\n",
    "            #     node = value_to_index_mapping[stringid]\n",
    "            group_node.append(stringid)\n",
    "    if len(set(group_node)) != 1:\n",
    "        complexs_id[complex_name] = group_node\n",
    "    else:\n",
    "        print(complex_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = []\n",
    "precision_col = []\n",
    "coverage_col = []\n",
    "for complex_name in complexs_id:\n",
    "    col1.append(complex_name)\n",
    "    points = complexs_id[complex_name]\n",
    "    for top in [20]:\n",
    "        precision = []\n",
    "        coverage = []\n",
    "        for start_gene in points:\n",
    "            test_nodes = list(set(points)-set(start_gene))\n",
    "            true_pre = []\n",
    "            subdf = network[network['protein1']==start_gene]\n",
    "            ranked = subdf.sort_values(by='combined_score')\n",
    "            predicted=ranked[:top]['protein2'].tolist()\n",
    "            for i in predicted:\n",
    "                if i in test_nodes:\n",
    "                    true_pre.append(i)\n",
    "            precision.append(len(true_pre)/len(predicted))\n",
    "            coverage.append(len(set(true_pre))/len(test_nodes))\n",
    "        # print('top-',top,'\\t',complex_name,' precision: ', sum(precision)/len(precision))\n",
    "        # print(complex_name,' coverage: ', sum(coverage)/len(coverage))\n",
    "        precision_col.append(sum(precision)/len(precision))\n",
    "        coverage_col.append(sum(coverage)/len(coverage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'sp_detailed_top20'\n",
    "result = pd.DataFrame({'complex': col1, 'precision_20':precision_col,'coverage_20':coverage_col})\n",
    "results_name = name +'.csv'\n",
    "result.to_csv('D:/study/thesis/project/HBDM-main/ppi_results/test_results/complexes/'+results_name,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
