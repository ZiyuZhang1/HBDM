{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook take protein embeddings from HBDM as input, using RF, KNN, SVC, ANN to classify protein binary classes (TF,drug-target,enzyme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\study\\thesis\\project\\HBDM-main\\data\\datasets\\ppi\\ppi_index.pkl', 'rb') as file:\n",
    "    ppi_index = pickle.load(file)\n",
    "with open(r'D:\\study\\thesis\\project\\HBDM-main\\data\\datasets\\ppi\\ppi_aliases2stringId.pkl', 'rb') as file:\n",
    "    aliases2stringId = pickle.load(file)\n",
    "with open(r'D:\\study\\thesis\\project\\HBDM-main\\data\\datasets\\ppi\\ppi_name2stringId.pkl', 'rb') as file:\n",
    "    name2stringId = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stringId(alias):\n",
    "    try:\n",
    "        stringId = name2stringId[alias]\n",
    "    except:\n",
    "        #print(alias, 'can\\'t be converted by name2stringId! Now trying aliases2stringId.')\n",
    "        try:\n",
    "            stringId = aliases2stringId[alias]\n",
    "        except:\n",
    "            #print(alias, 'can\\'t be converted by aliases2stringId! Now return None.')\n",
    "            stringId = None\n",
    "    #print(alias, stringId)\n",
    "    return stringId\n",
    "\n",
    "def load_data(root):\n",
    "    file_path_d = root+'/latent.pkl'\n",
    "    with open(file_path_d, 'rb') as file:\n",
    "        node_rep = pickle.load(file)\n",
    "\n",
    "    # tensor = loaded_tensor.cpu()\n",
    "    # node_rep = tensor.detach().numpy()\n",
    "\n",
    "    node_rep = np.array(node_rep)\n",
    "    df_latent = pd.DataFrame()\n",
    "    for d in range(node_rep.shape[1]):\n",
    "        col_name = str(d+1)+'d'\n",
    "        df_latent[col_name] = node_rep.T[d]\n",
    "    df_latent['node'] = df_latent.index\n",
    "\n",
    "    df = df_latent\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'Dataset-ppi--RE-True--W-2--Epochs-15000--D-4--RH-25--LR-0.1--LP-False--CUDA-True'\n",
    "name = 'Dataset-ppi--RE-True--W-2--Epochs-15000--D-4--RH-25--LR-0.1--LP-False--CUDA-True'\n",
    "root = 'D:/study/thesis/project/HBDM-main/ppi_results/models/'+name\n",
    "# dataset = 'n_ppi_g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_g = load_data(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetpath = r'D:\\study\\thesis\\project\\HBDM-main\\data\\protein_class\\target.tsv'\n",
    "with open(targetpath, 'r') as file:\n",
    "    lines = [line.strip().split('\\t')[0] for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw enzume data process\n",
    "# enzyme_path =r'D:\\study\\thesis\\project\\HBDM-main\\data\\protein_class\\enzyme.dat'\n",
    "# # Open the file and read lines that start with 'DR'\n",
    "# with open(enzyme_path, 'r') as file:\n",
    "#     dr_lines = [line.strip() for line in file if line.startswith('DR')]\n",
    "# human_enzymes = []\n",
    "\n",
    "# for line in dr_lines:\n",
    "#     words = line.split(' ')\n",
    "#     for i, txt in enumerate(words):\n",
    "#         if 'HUMAN' in txt:\n",
    "#             collected_value = words[i - 1].strip(',')\n",
    "#             human_enzymes.append(collected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = r'D:\\study\\thesis\\project\\HBDM-main\\data\\protein_class\\target.txt'\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for enzyme in lines:\n",
    "        output_file.write(enzyme + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rescal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
