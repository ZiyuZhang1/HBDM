{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.model_selection import KFold\n",
    "####loadfile\n",
    "with open(r'D:\\study\\thesis\\project\\HBDM-main\\data\\datasets\\ppi\\ppi_aliases2stringId.pkl', 'rb') as f:\n",
    "    ppi_name2stringId = pickle.load(f)\n",
    "with open(r'D:\\study\\thesis\\project\\HBDM-main\\data\\datasets\\ppi\\ppi_name2stringId.pkl', 'rb') as file:\n",
    "    name2stringId = pickle.load(file)\n",
    "with open('D:/study/thesis/project/HBDM-main/data/datasets/st/ppi_index.pkl', 'rb') as f:\n",
    "    st_dict = pickle.load(f)   \n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models = ['Dataset-st--RE-True--W-True--Epochs-15000--D-4--RH-25--LR-0.1--LP-False--CUDA-True',\n",
    "                  'Dataset-ppi--RE-True--W-True--Epochs-15000--D-4--RH-25--LR-0.1--LP-False--CUDA-True']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set(ppi_name2stringId.keys())\n",
    "tissue_genes = set(st_dict.keys())\n",
    "\n",
    "disease_root = r'D:\\study\\thesis\\project\\HBDM-main\\data\\disease'\n",
    "output_root = r'D:\\study\\thesis\\project\\HBDM-main\\ppi_results\\test_results'\n",
    "disease_list = ['Atherosclerosis.tsv','Cardiovascular_Diseases.tsv','Coronary_artery_disease.tsv','Coronary_heart_disease.tsv','Myocardial_Infarction.tsv']\n",
    "\n",
    "def convert_stringId(alias):\n",
    "    try:\n",
    "        stringId = name2stringId[alias]\n",
    "    except:\n",
    "        #print(alias, 'can\\'t be converted by name2stringId! Now trying aliases2stringId.')\n",
    "        try:\n",
    "            stringId = ppi_name2stringId[alias]\n",
    "        except:\n",
    "            #print(alias, 'can\\'t be converted by aliases2stringId! Now return None.')\n",
    "            stringId = None\n",
    "    #print(alias, stringId)\n",
    "    return stringId\n",
    "def folder_check(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    else:\n",
    "        pass\n",
    "def get_disease_genes(disease_df,tissue_genes,value_to_index_mapping):\n",
    "    network_genes = set(value_to_index_mapping.keys())\n",
    "    group_node = set()\n",
    "    for gene in disease_df['Gene']:\n",
    "        if gene in names:\n",
    "            stringid = convert_stringId(gene)\n",
    "            if stringid in tissue_genes:\n",
    "                if stringid in network_genes:         \n",
    "                    node = value_to_index_mapping[stringid]\n",
    "                    group_node.add(node)\n",
    "    return list(group_node)\n",
    "def calculate_precision_recall_curve(y_true, y_scores):\n",
    "    # Sort the scores and true labels in descending order of scores\n",
    "    desc_score_indices = np.argsort(y_scores)[::-1]\n",
    "    y_scores = np.array(y_scores)[desc_score_indices]\n",
    "    y_true = np.array(y_true)[desc_score_indices]\n",
    "\n",
    "    precision_values = []\n",
    "    recall_values = []\n",
    "    num_true_positives = 0\n",
    "    num_predicted_positives = 0\n",
    "    total_true_positives = sum(y_true)\n",
    "    \n",
    "    for i in range(len(y_true)):\n",
    "        num_predicted_positives += 1\n",
    "        if y_true[i] == 1:\n",
    "            num_true_positives += 1\n",
    "        precision = num_true_positives / num_predicted_positives\n",
    "        recall = num_true_positives / total_true_positives\n",
    "        precision_values.append(precision)\n",
    "        recall_values.append(recall)\n",
    "\n",
    "    return precision_values, recall_values\n",
    "\n",
    "def calculate_auc_pr(precision, recall):\n",
    "    return np.trapz(precision, recall)\n",
    "def find_best_thresholds(precision, recall, thresholds):\n",
    "    best_f1 = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_precision_threshold = thresholds[0]\n",
    "    best_recall_threshold = thresholds[0]\n",
    "    best_f1_threshold = thresholds[0]\n",
    "    for i in range(len(thresholds)):\n",
    "        if precision[i] + recall[i] != 0:\n",
    "            f1 = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "\n",
    "            if precision[i] > best_precision:\n",
    "                best_precision = precision[i]\n",
    "                # best_precision_threshold = thresholds[i]\n",
    "                best_precision_threshold = i\n",
    "            if recall[i] > best_recall:\n",
    "                best_recall = recall[i]\n",
    "                # best_recall_threshold = thresholds[i]\n",
    "                best_recall_threshold=i\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                # best_f1_threshold = thresholds[i]\n",
    "                best_f1_threshold = i\n",
    "\n",
    "    return best_f1_threshold, best_f1\n",
    "def results_f1_aucpr(predicted_positives,true_positives,plot=False):\n",
    "    # Example usage\n",
    "    precision_values, recall_values = calculate_precision_recall_curve(true_positives, predicted_positives)\n",
    "    auc_pr = calculate_auc_pr(precision_values, recall_values)\n",
    "\n",
    "\n",
    "\n",
    "    # Obtain the corresponding thresholds\n",
    "    thresholds = sorted(predicted_positives, reverse=True)\n",
    "\n",
    "    best_f1_threshold, best_f1, = find_best_thresholds(precision_values, recall_values, thresholds)\n",
    "\n",
    "    # print(\"Best Threshold for F1:\", best_f1_threshold)\n",
    "    # print(\"Best F1:\", best_f1)\n",
    "    # print('precision here ', precision_values[best_f1_threshold])\n",
    "    # print('recall here ', recall_values[best_f1_threshold])\n",
    "    # print(\"AUC-PR:\", auc_pr)\n",
    "    if plot:\n",
    "        # Plot the Precision-Recall curve\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(recall_values, precision_values, marker='o', linestyle='-')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.grid(True)\n",
    "\n",
    "        line_colors = ['r', 'b', 'g', 'y']\n",
    "\n",
    "        # Add vertical lines at i=10, i=50, i=100, and i=200 with different colors\n",
    "        top_cuts = [10, 50, 100, 200]\n",
    "\n",
    "        for i, top_cut in enumerate(top_cuts):\n",
    "            color_index = i % len(line_colors)  # Cyclically select colors from the list\n",
    "            plt.axvline(x=recall_values[top_cut], color=line_colors[color_index], linestyle='--', label=f'Top {top_cut}')\n",
    "        # Show or save the plot\n",
    "        plt.legend()  # Add a legend to explain the vertical lines\n",
    "        plt.show()\n",
    "\n",
    "    return [best_f1, auc_pr]\n",
    "def test_f1_auc(file_name,group_node,df):\n",
    "    # Define your range of k values and leaf_size values\n",
    "    k_values = range(2,10)\n",
    "\n",
    "    # Split your data into 5 folds\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    with open(file_name, \"w\") as f:\n",
    "        for k in k_values:\n",
    "            k+=1\n",
    "            results = []\n",
    "\n",
    "            # Build a k-d tree from the points\n",
    "            kdtree = KDTree(df[[col for col in df.columns if col.endswith('d')]].to_numpy(), leaf_size=20)\n",
    "            for train_index, test_index in kf.split(group_node):\n",
    "                train_nodes = [group_node[i] for i in train_index]\n",
    "                test_nodes = [group_node[i] for i in test_index]\n",
    "                start = []\n",
    "                dist = []\n",
    "                neighbor = []\n",
    "                random_nodes = []\n",
    "                for i in train_nodes:\n",
    "                    given_point = df[df['node']==i][[col for col in df.columns if col.endswith('d')]].to_numpy()\n",
    "                    # Perform a k-NN search to find the k+1 nearest neighbors\n",
    "                    distances, indices = kdtree.query(given_point, k=k)\n",
    "                    start += (k-1)*[i]\n",
    "                    dist += distances.reshape(-1).tolist()[1:]\n",
    "                    neighbor += indices.reshape(-1).tolist()[1:]\n",
    "                # random_nodes = random.sample(list(set(df['node'].tolist())-set(train_nodes)), (k-1))\n",
    "\n",
    "                neighbor_df = pd.DataFrame({'start': start, 'neighbor': neighbor, 'distance': dist})\n",
    "                neighbor_df = neighbor_df[~neighbor_df['neighbor'].isin(train_nodes)]\n",
    "                predict_df = neighbor_df['neighbor'].value_counts().to_frame()\n",
    "                predict_df.reset_index(inplace=True)\n",
    "                predict_df['true'] = predict_df.apply(lambda row: 1 if row['neighbor'] in test_nodes else 0, axis=1)\n",
    "                predicted_positives = predict_df['count']\n",
    "                true_positives = predict_df['true']\n",
    "                results.append(results_f1_aucpr(predicted_positives,true_positives))\n",
    "            results = np.array(results)\n",
    "            f1 = np.mean(results[:, 0])\n",
    "            auc = np.mean(results[:, 1])\n",
    "            # print(f\"k={k-1}, leaf_size={20}\",'\\t',\"F1:\", f1,'\\t',\"AUC_PR:\", auc)\n",
    "            print(f\"k={k-1}, leaf_size={20}\\tF1: {f1}\\tAUC_PR: {auc}\", file=f)\n",
    "#####\n",
    "### get node and 1d,2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_df(name):\n",
    "    dataset = name.split('--')[0].split('-')[1]\n",
    "    file_path_d = 'D:/study/thesis/project/HBDM-main/ppi_results/latent/'+name +'.pkl'\n",
    "    with open(file_path_d, 'rb') as file:\n",
    "        loaded_tensor = pickle.load(file)\n",
    "\n",
    "    tensor = loaded_tensor.cpu()\n",
    "    node_rep = tensor.detach().numpy()\n",
    "\n",
    "\n",
    "    df_latent = pd.DataFrame()\n",
    "    for d in range(node_rep.shape[1]):\n",
    "        col_name = str(d+1)+'d'\n",
    "        df_latent[col_name] = node_rep.T[d]\n",
    "    df_latent['node'] = df_latent.index\n",
    "    \n",
    "    with open('D:/study/thesis/project/HBDM-main/data/datasets/'+dataset+'/ppi_index.pkl', 'rb') as f:\n",
    "        value_to_index_mapping = pickle.load(f)    \n",
    "    return df_latent, value_to_index_mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage1 = get_latent_df(compare_models[0])\n",
    "usage2 = get_latent_df(compare_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = usage1[0]\n",
    "df1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_disease_genes() missing 1 required positional argument: 'value_to_index_mapping'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\study\\thesis\\project\\HBDM-main\\results_analysis_code\\combined_end.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study/thesis/project/HBDM-main/results_analysis_code/combined_end.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m folder_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_root,filename\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/thesis/project/HBDM-main/results_analysis_code/combined_end.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m folder_check(folder_path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/study/thesis/project/HBDM-main/results_analysis_code/combined_end.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m group_node \u001b[39m=\u001b[39m get_disease_genes(disease_df,tissue_genes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/thesis/project/HBDM-main/results_analysis_code/combined_end.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(filename\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(group_node))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/thesis/project/HBDM-main/results_analysis_code/combined_end.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m file_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder_path,name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: get_disease_genes() missing 1 required positional argument: 'value_to_index_mapping'"
     ]
    }
   ],
   "source": [
    "for filename in disease_list[0]:\n",
    "    if filename.endswith('txt'):\n",
    "        disease_df = pd.read_csv(os.path.join(disease_root,filename))\n",
    "    elif 'drug' in filename:\n",
    "        disease_df = pd.read_csv(os.path.join(disease_root,filename),sep='\\t')\n",
    "        disease_df['Gene']=disease_df['symbol']\n",
    "    elif filename.endswith('tsv'):\n",
    "        disease_df = pd.read_csv(os.path.join(disease_root,filename),sep='\\t')\n",
    "    folder_path = os.path.join(output_root,filename.split('.')[0])\n",
    "    folder_check(folder_path)\n",
    "    group_node = get_disease_genes(disease_df,tissue_genes)\n",
    "    # print(filename.split('.')[0], len(group_node))\n",
    "    # file_name = os.path.join(folder_path,name+'.txt')\n",
    "    # test_f1_auc(file_name,group_node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rescal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
