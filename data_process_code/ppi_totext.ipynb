{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load string db and get combined score ppi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_stringdb = 'D:/study/thesis/project/HBDM-main/nn_data/stringdb/'\n",
    "# load local STRING database and names\n",
    "df = pd.read_csv(local_stringdb+'9606.protein.info.v12.0.txt', sep='\\t', header=0, usecols=['#string_protein_id', 'preferred_name'])\n",
    "df['preferred_name'] = df['preferred_name'].str.upper()\n",
    "stringId2name = df.set_index('#string_protein_id')['preferred_name'].to_dict()\n",
    "name2stringId = df.set_index('preferred_name')['#string_protein_id'].to_dict()\n",
    "df = pd.read_csv(local_stringdb+'9606.protein.aliases.v12.0.txt', sep='\\t', header=0, usecols=['#string_protein_id', 'alias']).drop_duplicates(['alias'], keep='first')\n",
    "df['alias'] = df['alias'].str.upper()\n",
    "aliases2stringId = df.set_index('alias')['#string_protein_id'].to_dict()\n",
    "\n",
    "#string_score_transform = lambda x: -np.log(x/1000)\n",
    "\n",
    "graph_df = pd.read_csv(local_stringdb+'9606.protein.physical.links.detailed.v12.0.txt', sep=' ', header=0).convert_dtypes().replace(0, float('nan'))\n",
    "#network['combined_score'] = network['combined_score'].apply(string_score_transform)\n",
    "graph_df = graph_df[['protein1', 'protein2','combined_score']]\n",
    "graph_df['protein1'] = graph_df['protein1'].str.replace('9606.ENSP', '')\n",
    "graph_df['protein2'] = graph_df['protein2'].str.replace('9606.ENSP', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_path = r'D:\\study\\thesis\\project\\HBDM-main\\datasets\\ppi\\Aliases2stringId.pkl'\n",
    "\n",
    "# Serialize and save the Tensor to the file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(aliases2stringId, file)\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein1</th>\n",
       "      <th>protein2</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000000233</td>\n",
       "      <td>00000257770</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000000233</td>\n",
       "      <td>00000226004</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000000233</td>\n",
       "      <td>00000434442</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      protein1     protein2  combined_score\n",
       "0  00000000233  00000257770             311\n",
       "1  00000000233  00000226004             161\n",
       "2  00000000233  00000434442             499"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477610"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter with a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477610"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 100\n",
    "graph_df = graph_df[graph_df['combined_score'] >= threshold]\n",
    "len(graph_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805326\n",
      "18767\n",
      "(2, 805326)\n"
     ]
    }
   ],
   "source": [
    "uniquepair = set()\n",
    "nodes = set()\n",
    "sub_graph_df = graph_df[['protein1', 'protein2']]\n",
    "sub_graph_array = np.array(sub_graph_df.to_numpy(), dtype=int)\n",
    "for subarray in sub_graph_array:\n",
    "    result_string = '-'.join(map(str, set(subarray)))\n",
    "    uniquepair.add(result_string)\n",
    "    nodes.update(set(subarray))\n",
    "print(len(uniquepair))\n",
    "print(len(nodes))\n",
    "\n",
    "result_array = np.sort(np.array([list(map(int, item.split('-'))) for item in uniquepair]))\n",
    "value_to_index_mapping = {value: index for index, value in enumerate(sorted(list(nodes)))}\n",
    "mapped_arr = np.vectorize(value_to_index_mapping.get)(result_array)\n",
    "\n",
    "output = mapped_arr.T\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stringint2name = {int(key.split('.')[-1][-11:]): value for key, value in stringId2name.items()}\n",
    "# index2name = {value: stringint2name[key] for key, value in value_to_index_mapping.items()}\n",
    "# len(index2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2index = {value: key for key, value in value_to_index_mapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = 'D:/study/thesis/project/HBDM-main/datasets/ppi/'\n",
    "np.savetxt(savepath+'sparse_i.txt', output[0], delimiter='\\n')\n",
    "np.savetxt(savepath+'sparse_j.txt', output[1], delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = savepath+'ppi_index.pkl'\n",
    "\n",
    "# Serialize and save the Tensor to the file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(value_to_index_mapping, file)\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18767"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(graph_df['protein1'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\study\\thesis\\project\\HBDM-main\\data_process_code\\ppi_totext.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study/thesis/project/HBDM-main/data_process_code/ppi_totext.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# if the head half is the deduplicated\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/study/thesis/project/HBDM-main/data_process_code/ppi_totext.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m split_index \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(graph_array) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study/thesis/project/HBDM-main/data_process_code/ppi_totext.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test \u001b[39m=\u001b[39m graph_array[:split_index]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study/thesis/project/HBDM-main/data_process_code/ppi_totext.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(test, unique_elements):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'graph_array' is not defined"
     ]
    }
   ],
   "source": [
    "# if the head half is the deduplicated\n",
    "split_index = len(graph_array) // 2\n",
    "test = graph_array[:split_index]\n",
    "if np.array_equal(test, unique_elements):\n",
    "    print('The arrays are equal.')\n",
    "else:\n",
    "    print('The arrays are not equal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = savepath+'ppi_name2stringId.pkl'\n",
    "\n",
    "# Serialize and save the Tensor to the file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(name2stringId, file)\n",
    "# Close the file\n",
    "file.close()\n",
    "\n",
    "file_path = savepath+'ppi_aliases2stringId.pkl'\n",
    "\n",
    "# Serialize and save the Tensor to the file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(aliases2stringId, file)\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
