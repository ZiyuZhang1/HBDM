{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load string db and get combined score ppi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "local_stringdb = 'D:/study/thesis/project/HBDM-main/nn_data/stringdb/'\n",
    "# load local STRING database and names\n",
    "df = pd.read_csv(local_stringdb+'9606.protein.info.v12.0.txt', sep='\\t', header=0, usecols=['#string_protein_id', 'preferred_name'])\n",
    "df['preferred_name'] = df['preferred_name'].str.upper()\n",
    "stringId2name = df.set_index('#string_protein_id')['preferred_name'].to_dict()\n",
    "name2stringId = df.set_index('preferred_name')['#string_protein_id'].to_dict()\n",
    "df = pd.read_csv(local_stringdb+'9606.protein.aliases.v12.0.txt', sep='\\t', header=0, usecols=['#string_protein_id', 'alias']).drop_duplicates(['alias'], keep='first')\n",
    "df['alias'] = df['alias'].str.upper()\n",
    "aliases2stringId = df.set_index('alias')['#string_protein_id'].to_dict()\n",
    "\n",
    "#string_score_transform = lambda x: -np.log(x/1000)\n",
    "\n",
    "graph_df = pd.read_csv(local_stringdb+'9606.protein.physical.links.detailed.v12.0.txt', sep=' ', header=0).convert_dtypes().replace(0, float('nan'))\n",
    "#network['combined_score'] = network['combined_score'].apply(string_score_transform)\n",
    "graph_df = graph_df[['protein1', 'protein2','combined_score']]\n",
    "graph_df['protein1'] = graph_df['protein1'].str.replace('9606.ENSP', '')\n",
    "graph_df['protein2'] = graph_df['protein2'].str.replace('9606.ENSP', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477610"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_df['combined_score'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_df['combined_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "224528\n",
      "261914\n",
      "89013\n",
      "77659\n",
      "37577\n",
      "20331\n",
      "16114\n",
      "29260\n",
      "48930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "805326"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'D:\\study\\thesis\\project\\HBDM-main\\datasets\\ppi\\ppi_index.pkl', 'rb') as f:\n",
    "    value_to_index_mapping = pickle.load(f)\n",
    "len(value_to_index_mapping)\n",
    "nodes = set()\n",
    "n = 0\n",
    "for level in range(10):\n",
    "    threshold = level*100\n",
    "    sub_graph_df = graph_df[(graph_df['combined_score'] >= threshold) & (graph_df['combined_score'] < (threshold + 100))]\n",
    "    if len(sub_graph_df) == 0:\n",
    "        print('1')\n",
    "    else:\n",
    "        uniquepair = set()\n",
    "        sub_graph_df = sub_graph_df[['protein1', 'protein2']]\n",
    "        sub_graph_array = np.array(sub_graph_df.to_numpy(), dtype=int)\n",
    "        for subarray in sub_graph_array:\n",
    "            result_string = '-'.join(map(str, set(subarray)))\n",
    "            uniquepair.add(result_string)\n",
    "            nodes.update(set(subarray))\n",
    "        print(len(uniquepair))\n",
    "       \n",
    "        n+=len(uniquepair)\n",
    "        result_array = np.sort(np.array([list(map(int, item.split('-'))) for item in uniquepair]))\n",
    "        mapped_arr = np.vectorize(value_to_index_mapping.get)(result_array)\n",
    "        output = mapped_arr.T\n",
    "        savepath = 'D:/study/thesis/project/HBDM-main/datasets/ppi/level_'+str(level)\n",
    "        np.savetxt(savepath+'_sparse_i.txt', output[0], delimiter='\\n')\n",
    "        np.savetxt(savepath+'_sparse_j.txt', output[1], delimiter='\\n')\n",
    "n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18767"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18767"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(value_to_index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
