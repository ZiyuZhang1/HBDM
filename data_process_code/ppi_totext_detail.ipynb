{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_stringdb = '/novo/omdb/pds02/PDS2843/data/sprint_tid_ascvd/data/string/lfs-stringdb/'# load local STRING database and names\n",
    "df = pd.read_csv(local_stringdb+'9606.protein.info.v12.0.txt', sep='\\t', header=0, usecols=['#string_protein_id', 'preferred_name'])\n",
    "df['preferred_name'] = df['preferred_name'].str.upper()\n",
    "stringId2name = df.set_index('#string_protein_id')['preferred_name'].to_dict()\n",
    "name2stringId = df.set_index('preferred_name')['#string_protein_id'].to_dict()\n",
    "df = pd.read_csv(local_stringdb+'9606.protein.aliases.v12.0.txt', sep='\\t', header=0, usecols=['#string_protein_id', 'alias']).drop_duplicates(['alias'], keep='first')\n",
    "df['alias'] = df['alias'].str.upper()\n",
    "aliases2stringId = df.set_index('alias')['#string_protein_id'].to_dict()\n",
    "\n",
    "#string_score_transform = lambda x: -np.log(x/1000)\n",
    "\n",
    "graph_df = pd.read_csv(local_stringdb+'9606.protein.physical.links.detailed.v12.0.txt', sep=' ', header=0).convert_dtypes().replace(0, float('nan'))\n",
    "#network['combined_score'] = network['combined_score'].apply(string_score_transform)\n",
    "graph_df = graph_df[['protein1', 'protein2','combined_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(graph_df, source='protein1', target='protein2', edge_attr='combined_score', create_using=nx.Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Component 1\n",
      "nodes 18758 Edges: 738800\n",
      "Component 2\n",
      "nodes 2 Edges: 1\n",
      "Component 3\n",
      "nodes 2 Edges: 1\n",
      "Component 4\n",
      "nodes 2 Edges: 1\n",
      "Component 5\n",
      "nodes 3 Edges: 2\n"
     ]
    }
   ],
   "source": [
    "print(nx.is_connected(G))\n",
    "components = list(nx.connected_components(G))\n",
    "#Print information about each connected component\n",
    "for i, component in enumerate(components):\n",
    "    print(f\"Component {i + 1}\")\n",
    "\n",
    "    # Extract the edges for each component\n",
    "    subgraph = G.subgraph(component)\n",
    "    component_edges = subgraph.edges()\n",
    "    print('nodes',len(subgraph.nodes),'Edges:',len(subgraph.edges))\n",
    "\n",
    "subgraph = G.subgraph(components[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = nx.to_pandas_edgelist(subgraph, source='protein1', target='protein2')\n",
    "proteins = sorted(list(set(graph_df['protein1'].tolist())|set(graph_df['protein2'].tolist())))\n",
    "gene2node = {value: index for index, value in enumerate(proteins)}\n",
    " \n",
    "file_path ='/novo/omdb/pds02/PDS2843/data/sprint_tid_ascvd/gzn/thesis/HBDM/data/datasets/ppi/ppi_index.pkl'\n",
    "# Serialize and save the Tensor to the file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(gene2node, file)\n",
    "# Close the file\n",
    "file.close()\n",
    "\n",
    "graph_df['node1']=graph_df['protein1'].map(gene2node)\n",
    "graph_df['node2']=graph_df['protein2'].map(gene2node)\n",
    "G = nx.from_pandas_edgelist(graph_df, source='node1', target='node2', edge_attr='combined_score', create_using=nx.Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein1</th>\n",
       "      <th>protein2</th>\n",
       "      <th>combined_score</th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000257770</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>1914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000226004</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000434442</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>15871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000262455</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000303145</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>5073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738795</th>\n",
       "      <td>9606.ENSP00000359100</td>\n",
       "      <td>9606.ENSP00000359096</td>\n",
       "      <td>900</td>\n",
       "      <td>10097</td>\n",
       "      <td>10095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738796</th>\n",
       "      <td>9606.ENSP00000375108</td>\n",
       "      <td>9606.ENSP00000441197</td>\n",
       "      <td>323</td>\n",
       "      <td>12389</td>\n",
       "      <td>16123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738797</th>\n",
       "      <td>9606.ENSP00000344260</td>\n",
       "      <td>9606.ENSP00000357086</td>\n",
       "      <td>225</td>\n",
       "      <td>8191</td>\n",
       "      <td>9710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738798</th>\n",
       "      <td>9606.ENSP00000479624</td>\n",
       "      <td>9606.ENSP00000477530</td>\n",
       "      <td>800</td>\n",
       "      <td>17428</td>\n",
       "      <td>17253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738799</th>\n",
       "      <td>9606.ENSP00000444747</td>\n",
       "      <td>9606.ENSP00000356518</td>\n",
       "      <td>190</td>\n",
       "      <td>16268</td>\n",
       "      <td>9589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738800 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    protein1              protein2  combined_score  node1  \\\n",
       "0       9606.ENSP00000000233  9606.ENSP00000257770             311      0   \n",
       "1       9606.ENSP00000000233  9606.ENSP00000226004             161      0   \n",
       "2       9606.ENSP00000000233  9606.ENSP00000434442             499      0   \n",
       "3       9606.ENSP00000000233  9606.ENSP00000262455             531      0   \n",
       "4       9606.ENSP00000000233  9606.ENSP00000303145             499      0   \n",
       "...                      ...                   ...             ...    ...   \n",
       "738795  9606.ENSP00000359100  9606.ENSP00000359096             900  10097   \n",
       "738796  9606.ENSP00000375108  9606.ENSP00000441197             323  12389   \n",
       "738797  9606.ENSP00000344260  9606.ENSP00000357086             225   8191   \n",
       "738798  9606.ENSP00000479624  9606.ENSP00000477530             800  17428   \n",
       "738799  9606.ENSP00000444747  9606.ENSP00000356518             190  16268   \n",
       "\n",
       "        node2  \n",
       "0        1914  \n",
       "1         776  \n",
       "2       15871  \n",
       "3        2413  \n",
       "4        5073  \n",
       "...       ...  \n",
       "738795  10095  \n",
       "738796  16123  \n",
       "738797   9710  \n",
       "738798  17253  \n",
       "738799   9589  \n",
       "\n",
       "[738800 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df.to_csv('/novo/omdb/pds02/PDS2843/data/sprint_tid_ascvd/gzn/thesis/HBDM/data/ppi_connect.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = G.nodes()\n",
    "\n",
    "# Get all possible edges in the complete graph\n",
    "all_possible_edges = [(u, v) for u in nodes for v in nodes if u != v]\n",
    "\n",
    "# Get the existing edges in the graph\n",
    "existing_edges = list(G.edges())\n",
    "\n",
    "part_edges = sample(all_possible_edges,int(len(existing_edges)*1.3))\n",
    "non_existing_edges = list(set(part_edges) - set(existing_edges))\n",
    "selected_non_exist_edges = sample(non_existing_edges,int(len(existing_edges)*0.3))\n",
    "\n",
    "del all_possible_edges \n",
    "del part_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = nx.minimum_spanning_tree(G)\n",
    "sample_pool = list(set(existing_edges)-set(H.edges()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_edegs = sample(sample_pool, int(len(existing_edges)*0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.array([(u, v, data['combined_score']) for u, v, data in G.edges(data=True)])\n",
    "\n",
    "# Determine i, j, and weights\n",
    "i = np.where(edges[:, 0] > edges[:, 1], edges[:, 1], edges[:, 0])\n",
    "j = np.where(edges[:, 0] > edges[:, 1], edges[:, 0], edges[:, 1])\n",
    "weights = edges[:, 2]\n",
    "weights = weights*0.001\n",
    "\n",
    "root = '/novo/omdb/pds02/PDS2843/data/sprint_tid_ascvd/gzn/thesis/HBDM/data/datasets/ppi/'\n",
    "np.savetxt(root+'sparse_i.txt', np.array(i), delimiter='\\n')\n",
    "np.savetxt(root+'sparse_j.txt', np.array(j), delimiter='\\n')\n",
    "np.savetxt(root+'sparse_w.txt', np.array(weights), delimiter='\\n')\n",
    "\n",
    "weights = (weights*0.01).astype(int)\n",
    "np.savetxt(root+'sparse_10.txt', np.array(weights), delimiter='\\n')\n",
    "\n",
    "level_edges = dict()\n",
    "for u, v, data in G.edges(data=True):\n",
    "    level = int(str(data['combined_score'])[0])\n",
    "    if level in level_edges:\n",
    "        level_edges[level].append([u, v])\n",
    "    else:\n",
    "        level_edges[level]=[[u, v]]\n",
    "\n",
    "for level in level_edges:\n",
    "    edges = np.array(level_edges[level])\n",
    "    sparse_i = np.where(edges[:, 0] > edges[:, 1], edges[:, 1], edges[:, 0])\n",
    "    sparse_j = np.where(edges[:, 0] > edges[:, 1], edges[:, 0], edges[:, 1])\n",
    "    np.savetxt(root+'level_'+str(level)+'_sparse_i.txt', np.array(sparse_i), delimiter='\\n')\n",
    "    np.savetxt(root+'level_'+str(level)+'_sparse_j.txt', np.array(sparse_j), delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/novo/omdb/pds02/PDS2843/data/sprint_tid_ascvd/gzn/thesis/HBDM/data/datasets/ppi/ppi_index.pkl'\n",
    "# Serialize and save the Tensor to the file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(gene2node, file)\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingraph = G.edge_subgraph(list(set(existing_edges)-set(mask_edegs)))\n",
    "\n",
    "edges = np.array([(u, v, data['combined_score']) for u, v, data in traingraph.edges(data=True)])\n",
    "\n",
    "# Determine i, j, and weights\n",
    "i = np.where(edges[:, 0] > edges[:, 1], edges[:, 1], edges[:, 0])\n",
    "j = np.where(edges[:, 0] > edges[:, 1], edges[:, 0], edges[:, 1])\n",
    "weights = edges[:, 2]\n",
    "weights = weights*0.001\n",
    "root = '/novo/omdb/pds02/PDS2843/data/sprint_tid_ascvd/gzn/thesis/HBDM/data/datasets/ppi_linkpredict5/'\n",
    "np.savetxt(root+'sparse_i.txt', np.array(i), delimiter='\\n')\n",
    "np.savetxt(root+'sparse_j.txt', np.array(j), delimiter='\\n')\n",
    "np.savetxt(root+'sparse_w.txt', np.array(weights), delimiter='\\n')\n",
    "\n",
    "weights = (weights*0.01).astype(int)\n",
    "np.savetxt(root+'sparse_10.txt', np.array(weights), delimiter='\\n')\n",
    "\n",
    "level_edges = dict()\n",
    "for u, v, data in traingraph.edges(data=True):\n",
    "    level = int(str(data['combined_score'])[0])\n",
    "    if level in level_edges:\n",
    "        level_edges[level].append([u, v])\n",
    "    else:\n",
    "        level_edges[level]=[[u, v]]\n",
    "\n",
    "for level in level_edges:\n",
    "    edges = np.array(level_edges[level])\n",
    "    sparse_i = np.where(edges[:, 0] > edges[:, 1], edges[:, 1], edges[:, 0])\n",
    "    sparse_j = np.where(edges[:, 0] > edges[:, 1], edges[:, 0], edges[:, 1])\n",
    "    np.savetxt(root+'level_'+str(level)+'_sparse_i.txt', np.array(sparse_i), delimiter='\\n')\n",
    "    np.savetxt(root+'level_'+str(level)+'_sparse_j.txt', np.array(sparse_j), delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.array(mask_edegs)\n",
    "\n",
    "# Determine i, j, and weights\n",
    "i = np.where(edges[:, 0] > edges[:, 1], edges[:, 1], edges[:, 0])\n",
    "j = np.where(edges[:, 0] > edges[:, 1], edges[:, 0], edges[:, 1])\n",
    "\n",
    "np.savetxt(root+'sparse_i_rem.txt', np.array(i), delimiter='\\n')\n",
    "np.savetxt(root+'sparse_j_rem.txt', np.array(j), delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.array(selected_non_exist_edges)\n",
    "\n",
    "# Determine i, j, and weights\n",
    "i = np.where(edges[:, 0] > edges[:, 1], edges[:, 1], edges[:, 0])\n",
    "j = np.where(edges[:, 0] > edges[:, 1], edges[:, 0], edges[:, 1])\n",
    "\n",
    "np.savetxt(root+'non_sparse_i.txt', np.array(i), delimiter='\\n')\n",
    "np.savetxt(root+'non_sparse_j.txt', np.array(j), delimiter='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
