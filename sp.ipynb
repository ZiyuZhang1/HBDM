{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bi-network cad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\study\\thesis\\project\\HBDM-main\\data\\disease\\cad_node.pkl', 'rb') as file:\n",
    "    group_node = pickle.load(file)\n",
    "\n",
    "neighbor_df = pd.read_csv(r'D:\\study\\thesis\\project\\HBDM-main\\data\\cad_neighbors_temp_bi.csv')\n",
    "\n",
    "network = pd.read_csv(r'D:\\study\\thesis\\project\\HBDM-main\\data\\ppi_connect.csv')\n",
    "\n",
    "string_score_transform = lambda x: -np.log(x/1000)\n",
    "network['continuous'] = network['combined_score'].apply(string_score_transform)\n",
    "G = nx.from_pandas_edgelist(network, source='node1', target='node2', edge_attr='continuous', create_using=nx.Graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_df = pd.read_csv(r'D:\\study\\thesis\\project\\HBDM-main\\data\\cad_neighbors_temp_gg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.61128607, 0.62444633, 0.63327426, 0.61529834, 0.60204676,\n",
       "        0.59632893, 0.59240534]),\n",
       " array([0.1113451 , 0.10784364, 0.09063786, 0.0670033 , 0.05899256,\n",
       "        0.05597236, 0.05405914]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks = [3,5,10,25,50,75,100]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kfresults = []\n",
    "for train_index, test_index in kf.split(group_node):\n",
    "    train_nodes = [group_node[i] for i in train_index]\n",
    "    test_nodes = [group_node[i] for i in test_index]\n",
    "    \n",
    "    kfneighbor_df = neighbor_df[neighbor_df['start'].isin(train_nodes)]\n",
    "    results = []\n",
    "    groups = kfneighbor_df.groupby('start')\n",
    "    for k in ks:\n",
    "        \n",
    "        for i, (key, subdf) in enumerate(groups):\n",
    "            subdf = subdf.head(k)\n",
    "            if i == 0:\n",
    "                kneighbor_df = subdf\n",
    "            else:\n",
    "                kneighbor_df = pd.concat([kneighbor_df, subdf], ignore_index=True)\n",
    "        kneighbor_df = kneighbor_df[~kneighbor_df['neighbor'].isin(train_nodes)]\n",
    "        predict_df = kneighbor_df['neighbor'].value_counts().to_frame()\n",
    "        predict_df.reset_index(inplace=True)\n",
    "        predict_df.rename(columns={'neighbor':'count','index':'neighbor'},inplace=True)\n",
    "        predict_df['true'] = predict_df.apply(lambda row: 1 if row['neighbor'] in test_nodes else 0, axis=1)\n",
    "        if len(predict_df[predict_df['true']==1])==0:\n",
    "            results.append([0, 0])\n",
    "        else:\n",
    "            predicted_positives = predict_df['count']\n",
    "            true_positives = predict_df['true']\n",
    "            precision, recall, thresholds = metrics.precision_recall_curve(true_positives,predicted_positives)\n",
    "            roc,pr= metrics.roc_auc_score(true_positives,predicted_positives),metrics.auc(recall,precision)\n",
    "            results.append([roc,pr])\n",
    "    kfresults.append(results)\n",
    "kfresults = np.array(kfresults)\n",
    "all_res = np.mean(kfresults, axis=0)\n",
    "roc_ks = all_res[:, 0]\n",
    "pr_ks = all_res[:, 1]\n",
    "roc_ks,pr_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.558769396"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sp cad bi\n",
    "# (array([0.5587694 , 0.57828225, 0.59529003, 0.63259433, 0.66840065,\n",
    "#         0.69077752, 0.6935744 ]),\n",
    "#  array([0.06399026, 0.06378134, 0.06264023, 0.05992439, 0.05625323,\n",
    "#         0.05337278, 0.05063705]))\n",
    "# sp cad 10\n",
    "# [array([0.61457747, 0.62742304, 0.65243125, 0.65516545, 0.6492224 ,\n",
    "#        0.64148328, 0.63666845]), \n",
    "#        array([0.12010561, 0.10943346, 0.09786825, 0.08180575, 0.07165748,\n",
    "#        0.06702653, 0.06514911])]\n",
    "# sp cad gg\n",
    "# (array([0.61128607, 0.62444633, 0.63327426, 0.61529834, 0.60204676,\n",
    "#         0.59632893, 0.59240534]),\n",
    "#  array([0.1113451 , 0.10784364, 0.09063786, 0.0670033 , 0.05899256,\n",
    "#         0.05597236, 0.05405914]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ks:\n",
    "    kneighbor_df = pd.DataFrame()\n",
    "    for key, subdf in groups:\n",
    "        subdf = subdf.head(k)\n",
    "        kneighbor_df = pd.concat([kneighbor_df, subdf], ignore_index=True)\n",
    "    kneighbor_df = kneighbor_df[~kneighbor_df['neighbor'].isin(train_nodes)]\n",
    "    predict_df = kneighbor_df['neighbor'].value_counts().to_frame()\n",
    "    predict_df.reset_index(inplace=True)\n",
    "    predict_df.rename(columns={'neighbor':'count','index':'neighbor'},inplace=True)\n",
    "    predict_df['true'] = predict_df.apply(lambda row: 1 if row['neighbor'] in test_nodes else 0, axis=1)\n",
    "if len(predict_df[predict_df['true']==1])==0:\n",
    "    results.append([0, 0])\n",
    "else:\n",
    "    predicted_positives = predict_df['count']\n",
    "    true_positives = predict_df['true']\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(true_positives,predicted_positives)\n",
    "    roc,pr= metrics.roc_auc_score(true_positives,predicted_positives),metrics.auc(recall,precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:/study/thesis/project/HBDM-main/data/datasets/ppi_linkpredict/'\n",
    " \n",
    " \n",
    "sparse_i = np.loadtxt(root+'sparse_i.txt')\n",
    "sparse_j = np.loadtxt(root+'sparse_j.txt')\n",
    "sparse_w = np.loadtxt(root+'sparse_w.txt')\n",
    " \n",
    "sparse_i = sparse_i.astype(int)\n",
    "sparse_j = sparse_j.astype(int)\n",
    "sparse_w = sparse_w.astype(float)\n",
    " \n",
    "# string_score_transform = np.vectorize(lambda x: -np.log(x/1000))\n",
    "# transformed_w = string_score_transform(sparse_w)\n",
    "transformed_w = 11-(sparse_w*10).round()\n",
    "# edges_and_weights = zip(sparse_i, sparse_j,transformed_w)\n",
    " \n",
    "# G = nx.Graph()\n",
    " \n",
    "# # Use from_edgelist to directly create the graph from edges\n",
    "# G.add_weighted_edges_from(edges_and_weights)\n",
    "# len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(transformed_w == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_i_rem = np.loadtxt(root+'sparse_i_rem.txt')\n",
    "sparse_j_rem = np.loadtxt(root+'sparse_j_rem.txt')\n",
    "sparse_i_rem = sparse_i_rem.astype(int)[:10]\n",
    "sparse_j_rem = sparse_j_rem.astype(int)\n",
    "\n",
    "non_sparse_i = np.loadtxt(root+'non_sparse_i.txt')\n",
    "non_sparse_j = np.loadtxt(root+'non_sparse_j.txt')\n",
    "non_sparse_i = non_sparse_i.astype(int)\n",
    "non_sparse_j = non_sparse_j.astype(int)\n",
    "\n",
    "test_i = np.concatenate((sparse_i_rem, non_sparse_i))\n",
    "test_j = np.concatenate((sparse_j_rem, non_sparse_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = np.array([1]*sparse_i_rem.shape[0]+[0]*non_sparse_i.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = []\n",
    "for i, source in enumerate(test_i):\n",
    "    target = test_j[i]\n",
    "    try:\n",
    "        predict_label.append(1/nx.shortest_path_length(G, source=source, target=target,weight='weight'))\n",
    "    except nx.NetworkXNoPath:\n",
    "        predict_label.append(0)\n",
    "\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(true_label,predict_label)\n",
    "roc,pr= metrics.roc_auc_score(true_label,predict_label),metrics.auc(recall,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9030569430569431"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rescal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
